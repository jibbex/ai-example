<!doctype html>
<html lang="en">
    <!--attr-->
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title data-react-helmet="true">Generative Künstliche Intelligenz</title><meta data-react-helmet="true" name="keywords" property="Generative Künstliche Intelligenz, AI, GPT, Stable Diffusion, Maschinelles Lernen, Modelle, Techniken, Chancen, Gefahren" data-react-helmet="true"/><meta data-react-helmet="true" name="description" content="Generative AI umfasst ein sehr breites Spektrum von möglichen  Anwendungsfällen wie z.B. die Generation oder das Umformen von Textinhalten auf Basis unterschiedlichster Quellen, das Erzeugen von Multimedia Inhalten (Bilder, Videos, Audio) wobei die Ausgabe auch äußerst vielfältig sein kann, dem Erkennen von Mustern in Bildern oder Videos. und noch vielen mehr. " data-react-helmet="true"/><meta data-react-helmet="true" name="theme-color" content="#16324e" data-react-helmet="true"/><meta data-react-helmet="true" property="og:site_name" content="Generative Künstliche Intelligenz" data-react-helmet="true"/><meta data-react-helmet="true" property="og:type" content="website" data-react-helmet="true"/><meta data-react-helmet="true" property="og:title" content="Generative Künstliche Intelligenz" data-react-helmet="true"/><meta data-react-helmet="true" property="og:description" content="Generative AI umfasst ein sehr breites Spektrum von möglichen  Anwendungsfällen wie z.B. die Generation oder das Umformen von Textinhalten auf Basis unterschiedlichster Quellen, das Erzeugen von Multimedia Inhalten (Bilder, Videos, Audio) wobei die Ausgabe auch äußerst vielfältig sein kann, dem Erkennen von Mustern in Bildern oder Videos. und noch vielen mehr. " data-react-helmet="true"/><meta data-react-helmet="true" property="og:url" content="https://michm.de" data-react-helmet="true"/><meta data-react-helmet="true" property="og:image" content="/pixel-vault.png" data-react-helmet="true"/><meta data-react-helmet="true" property="twitter:title" content="Generative Künstliche Intelligenz" data-react-helmet="true"/><meta data-react-helmet="true" property="twitter:description" content="Generative AI umfasst ein sehr breites Spektrum von möglichen  Anwendungsfällen wie z.B. die Generation oder das Umformen von Textinhalten auf Basis unterschiedlichster Quellen, das Erzeugen von Multimedia Inhalten (Bilder, Videos, Audio) wobei die Ausgabe auch äußerst vielfältig sein kann, dem Erkennen von Mustern in Bildern oder Videos. und noch vielen mehr. " data-react-helmet="true"/><meta data-react-helmet="true" property="twitter:card" content="summary_large_image" data-react-helmet="true"/><meta data-react-helmet="true" property="twitter:url" content="https://michm.de" data-react-helmet="true"/><meta data-react-helmet="true" property="twitter:image" content="/pixel-vault.png" data-react-helmet="true"/>
    <link rel="icon" type="image/svg+xml" href="/ai-example/rocket.svg">
  <script type="module" crossorigin src="/ai-example/assets/index-CtK87oVN.js"></script>
  <link rel="stylesheet" crossorigin href="/ai-example/assets/index-D6AosUmA.css">
</head>

<body>
    <div id="root"><main class="section--bg relative z-[1] shadow-md"><section id="hero" style="min-height:90lvh;padding-bottom:10em"><h1 id="vault-title" class="absolute top-[100px] left-[2vw]" data-aos="zoom-out-right" data-aos-offset="0" data-aos-delay="200" data-aos-duration="1200" data-aos-anchor-placement="top-bottom" data-aos-mirror="true">Generative AI</h1><div class="card-track"><div class="card-wrapper"><div class="card"><div class="z-20 bottom-8 absolute" data-aos="zoom-in-left" data-aos-mirror="true" data-aos-offset="550" data-aos-duration="700" data-aos-delay="800" data-aos-anchor-placement="bottom-bottom" data-aos-anchor="#vault-title"><div class="py-20 flex items-center justify-center" style="perspective:1000px"><div class="flex items-center justify-center relative transition-all duration-200 ease-linear left-0 md:left-[25vw] md:bottom-[8em] lg:bottom-[10em]" style="transform-style:preserve-3d"><div class="[transform-style:preserve-3d] [&amp;&gt;*]:[transform-style:preserve-3d] bg-gradient-to-br overflow-visible p-6 to-[#671e75] from-[#fc4d02] relative group shadow-lg hover:shadow-2xl border-white/[0.4] border-2 min-w-[500px] w-full sm:w-[30rem] h-auto rounded-2xl"><div class="w-fit transition duration-200 ease-linear"><img src="/ai-example/assets/proxy-fT_8cQvV.jpg" alt="AI generated Image" class="image-vault shadow-lg shadow-slate-800 group-hover:shadow-2xl group-hover:shadow-slate-800"/></div><div class="w-fit transition duration-200 ease-linear p-6 bg-black/20 group-hover:bg-black/5 backdrop-blur-xl shadow-md shadow-slate-800/50 group-hover:shadow-2xl group-hover:shadow-slate-800/20 rounded-md my-2 mx-auto" style="with:calc(100% - 0.5rem)"><div>Entstand bei einer Erläuterung welche Aufgabe ein Reverse Proxy erfüllt.</div></div></div></div></div></div><div class="card-letters"></div></div></div></div></section><nav class="sticky top-0 z-[1300] left-[90%] inline-block"><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 bg-primary hover:bg-primary/90 h-10 w-10 border-white/[0.4] rounded-full focus:ring-2 ring-yellow-200 text-black hover:shadow-sm shadow-xl hover:backdrop-blur-lg m-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="size-6"><path fill-rule="evenodd" d="M4.5 5.653c0-1.427 1.529-2.33 2.779-1.643l11.54 6.347c1.295.712 1.295 2.573 0 3.286L7.28 19.99c-1.25.687-2.779-.217-2.779-1.643V5.653Z" clip-rule="evenodd"></path></svg></button></nav><section id="section--0" style="background-image:linear-gradient(320deg, rgba(103, 30, 117, 1) 11.2%, rgba(252, 76, 2, 1) 91.1%);box-shadow:0 0 -4em 12em rgba(0, 0, 0, 0.45);align-items:center;display:flex;flex-wrap:wrap;flex-direction:column;justify-content:flex-start;margin-top:-20lvh;clip-path:polygon(0 6%, 100% 0, 100% 105%, 0 100%);z-index:2"><h2 data-index="879e2183d4" type="5" content="Natural Language Processing" data-aos="zoom-out-up" data-aos-delay="1600" data-aos-offset="0" data-aos-anchor-placement="bottom-bottom" class="txt" style="font-weight:500;bottom:auto;position:relative;margin-top:0;left:auto;flex:0;color:transparent;background-clip:text;pointer-events:none;text-align:center;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));background-image:radial-gradient(circle 763px at 0%, rgb(241 197 194) 0%, rgb(245 215 117) 100%)">Natural Language Processing</h2><span data-index="13ff09cee47" type="3" content="GPT-Modelle (generative pre-trained transformer) gehören zu den Large Language Models (LLM) und wurden von OpenAI entwickelt. Sie sind so konzipiert, dass sie auf der Grundlage der Eingaben, die sie erhalten, einen menschlich ähnlichen Text erzeugen können. Hierbei wird eine Wahrscheinlichkeit auf Basis der zuvor generierten Wörter, der Eingabe und zusätzlich definierbaren Parameter berechnet um das Nächste zu erahnen. Dieses vorgehen kann hochwertigen Text erzeugen, wenn der Eingabe-Prompt akkurat und auch Aussagen zur Form der gewünschten Ausgabe erhält." data-aos-delay="0" data-aos="fade-left" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;fons-size:0.5em !important;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">GPT-Modelle (generative pre-trained transformer) gehören zu den Large Language Models (LLM) und wurden von OpenAI entwickelt. Sie sind so konzipiert, dass sie auf der Grundlage der Eingaben, die sie erhalten, einen menschlich ähnlichen Text erzeugen können. Hierbei wird eine Wahrscheinlichkeit auf Basis der zuvor generierten Wörter, der Eingabe und zusätzlich definierbaren Parameter berechnet um das Nächste zu erahnen. Dieses vorgehen kann hochwertigen Text erzeugen, wenn der Eingabe-Prompt akkurat und auch Aussagen zur Form der gewünschten Ausgabe erhält.</span><span data-index="b5dc6e4ef1" type="3" content="Öfter lässt sich allerdings auch eine Ausgabe ohne viel Aufwand als KI generiert identifizieren. Anhaltspunkte sind z.B. eine starke Häufung an Wortwiederholungen. Gerade das Angefragte Subjekt wird annährend in jeden Satz wiederholt, und Standard-Phrasen, die häufig von den Modellen erzeugt werden lassen sich auch leicht erkennen. Mit einem entsprechend trainierten Modell, ließe sich auch ein erkennendes System automatisieren. Das würde exakt auf die gleiche Technik zurückgreifen." data-aos-delay="0" data-aos="fade-right" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Öfter lässt sich allerdings auch eine Ausgabe ohne viel Aufwand als KI generiert identifizieren. Anhaltspunkte sind z.B. eine starke Häufung an Wortwiederholungen. Gerade das Angefragte Subjekt wird annährend in jeden Satz wiederholt, und Standard-Phrasen, die häufig von den Modellen erzeugt werden lassen sich auch leicht erkennen. Mit einem entsprechend trainierten Modell, ließe sich auch ein erkennendes System automatisieren. Das würde exakt auf die gleiche Technik zurückgreifen.</span><span data-index="b4c87fcd9b" type="3" content="Neben den GPT Modellen gibt es auch noch andere Modelle, die auf ähnlichen Prinzipien basieren. Einige davon sind auch Open Source und können von jedem genutzt werden. Unter anderem erwähnenswert ist Mistral von Mistral AI, Claude von Antrophic und auch llama von Ollama. Diese Modelle sind alle auf GitHub und Hugging Face verfügbar und können von jedem genutzt werden." data-aos-delay="0" data-aos="fade-left" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Neben den GPT Modellen gibt es auch noch andere Modelle, die auf ähnlichen Prinzipien basieren. Einige davon sind auch Open Source und können von jedem genutzt werden. Unter anderem erwähnenswert ist Mistral von Mistral AI, Claude von Antrophic und auch llama von Ollama. Diese Modelle sind alle auf GitHub und Hugging Face verfügbar und können von jedem genutzt werden.</span></section><section id="section--1" style="background-image:linear-gradient(14deg, rgb(252, 76, 2) 11.2%, rgb(103, 30, 117) 91.1%);box-shadow:0 0 12em rgba(0, 0, 0, 0.45);align-items:center;gap:2em;display:flex;flex-wrap:wrap;justify-content:space-between;zindex:7px;clip-path:polygon(0 6%, 100% 0, 100% 105%, 0 100%)"><h2 data-index="ea45a96899" type="5" content="LLM&#x27;s" data-aos="zoom-out-up" data-aos-delay="0" data-aos-offset="0" data-aos-anchor-placement="bottom-bottom" class="txt" style="display:block;font-weight:500;bottom:auto;position:relative;flex:1 1 100%;margin-top:0;left:auto;align-self:flex-start;color:transparent;background-clip:text;text-align:center;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));background-image:radial-gradient(circle 763px at 0%, rgb(241 197 194) 0%, rgb(245 215 117) 100%)">LLM&#x27;s</h2><img data-index="5498cfd72b" type="0" src="/bots2.png" alt="Some annoyed looking bots." data-aos="zoom-in-down" data-aos-delay="0" class="self-start radius-[2em]"/><img data-index="6c6a9d3ed5" type="0" alt="The Pixel Vault" data-aos="zoom-out-up" data-aos-delay="300" class="self-end radius-[2em]" src="/pixel-vault.jpg"/><span data-index="d2d37b1952" type="3" content="Typischerweise werden LLM&#x27;s für Textgenerierung, Textklassifikation, Textübersetzung, Feature-Extraktion, Zusammenfassungen und Textverständnis verwendet. Einige der bekanntesten Anwendungen sind Chatbots, Sprachassistenten, automatische Übersetzungsdienste und Textanalyse-Tools. LLM&#x27;s können auch für die Erstellung von Inhalten wie Blog-Posts, Produktbeschreibungen und Nachrichtenartikeln verwendet werden." data-aos-delay="0" data-aos="fade-right" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;fons-size:0.5em !important;margin:0;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Typischerweise werden LLM&#x27;s für Textgenerierung, Textklassifikation, Textübersetzung, Feature-Extraktion, Zusammenfassungen und Textverständnis verwendet. Einige der bekanntesten Anwendungen sind Chatbots, Sprachassistenten, automatische Übersetzungsdienste und Textanalyse-Tools. LLM&#x27;s können auch für die Erstellung von Inhalten wie Blog-Posts, Produktbeschreibungen und Nachrichtenartikeln verwendet werden.</span></section><section id="section--2" style="flex-wrap:wrap;gap:2em;box-shadow:box-shadow: 0 0 12em rgba(0 0 0 / 45%);background-image:linear-gradient(138deg, rgb(252, 76, 2) 11.2%, rgb(103, 30, 117) 130%);align-items:center;display:flex;flex-direction:column;justify-content:flex-start;z-index:12;clip-path:polygon(0 6%, 100% 0, 100% 105%, 0 100%)"><h2 data-index="7f8a8327d9" type="5" data-aos="zoom-out-up" data-aos-anchor-placement="center-center" class="txt" style="display:block;font-weight:500;bottom:auto;position:relative;margin:0;color:transparent;background-clip:text;text-align:center;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));background-image:radial-gradient(circle 763px at 0%, rgb(241 197 194) 0%, rgb(245 215 117) 100%)" content="Computer Vision">Computer Vision</h2><span data-index="83f22bd284" type="3" content="Computer Vision ist ein Bereich der künstlichen Intelligenz, der sich mit der Entwicklung von Algorithmen und Technologien befasst, die Computern das Sehen und Verstehen von Bildern und Videos ermöglichen. Computer Vision-Systeme können Objekte, Personen, Orte, Aktivitäten und andere visuelle Elemente in Bildern und Videos erkennen, klassifizieren und verarbeiten. Diese Systeme werden in einer Vielzahl von Anwendungen eingesetzt, darunter Gesichtserkennung, Objekterkennung, Bilderkennung, medizinische Bildgebung, autonome Fahrzeuge und Robotik." data-aos-delay="0" data-aos="fade-left" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;margin:0;fons-size:0.5em !important;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Computer Vision ist ein Bereich der künstlichen Intelligenz, der sich mit der Entwicklung von Algorithmen und Technologien befasst, die Computern das Sehen und Verstehen von Bildern und Videos ermöglichen. Computer Vision-Systeme können Objekte, Personen, Orte, Aktivitäten und andere visuelle Elemente in Bildern und Videos erkennen, klassifizieren und verarbeiten. Diese Systeme werden in einer Vielzahl von Anwendungen eingesetzt, darunter Gesichtserkennung, Objekterkennung, Bilderkennung, medizinische Bildgebung, autonome Fahrzeuge und Robotik.</span><span data-index="8c1315707e" type="3" content="So lassen sich beispielsweise aus Bildern und Videos eine Tiefenschätzung ableiten und daraus 3D-Modelle generieren. Um ein 3D-Modell aus den generierten Daten abzuleiten benötigt man das Ursprungsbild und die sogenannte Depth Map. Beide Bilder kann man dann mithilfe eines Algorithmuses, der in einen Shader rechnet zu einem 3D-Modell zusammenfügen. Ein Shader ist ein Programm, das auf der Grafikkarte ausgeführt wird und die Berechnungen für die Darstellung von 3D-Objekten übernimmt." data-aos-delay="0" data-aos="fade-right" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;margin:0;position:relative;fons-size:0.5em !important;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">So lassen sich beispielsweise aus Bildern und Videos eine Tiefenschätzung ableiten und daraus 3D-Modelle generieren. Um ein 3D-Modell aus den generierten Daten abzuleiten benötigt man das Ursprungsbild und die sogenannte Depth Map. Beide Bilder kann man dann mithilfe eines Algorithmuses, der in einen Shader rechnet zu einem 3D-Modell zusammenfügen. Ein Shader ist ein Programm, das auf der Grafikkarte ausgeführt wird und die Berechnungen für die Darstellung von 3D-Objekten übernimmt.</span></section><section id="section--3" style="background-image:linear-gradient(14deg, rgb(252, 76, 2) 11.2%, rgb(103, 30, 117) 91.1%);box-shadow:0 0 12em rgba(0, 0, 0, 0.45);align-items:center;display:flex;flex-wrap:wrap;flex-direction:column;justify-content:flex-start;z-index:16;clip-path:polygon(0 6%, 100% 0, 100% 105%, 0 100%)"><h2 data-index="1920647d81" type="5" data-aos="zoom-out-up" data-aos-anchor-placement="center-center" class="txt" style="display:block;font-weight:500;bottom:auto;position:relative;margin-top:0;left:auto;color:transparent;background-clip:text;text-align:center;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));background-image:radial-gradient(circle 763px at 0%, rgb(241 197 194) 0%, rgb(245 215 117) 100%)" content="Audio Processing">Audio Processing</h2><span data-index="cb08f15710" type="3" content="Audio Processing ist ein Bereich der künstlichen Intelligenz, der sich mit der Entwicklung von Algorithmen und Technologien befasst, die Computern das Verstehen und Verarbeiten von Audio ermöglichen. Audio Processing-Systeme können Sprache, Musik, Geräusche und andere akustische Signale erkennen, klassifizieren und verarbeiten. Diese Systeme werden in einer Vielzahl von Anwendungen eingesetzt, darunter Spracherkennung, Musikerkennung, Geräuschunterdrückung, Audioanalyse und Sprachsynthese." data-aos-delay="0" data-aos="fade-left" data-aos-anchor-placement="center-center" class="text-6xl md:text-8xl lg:text-10xl aos-init aos-animate" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;fons-size:0.5em !important;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Audio Processing ist ein Bereich der künstlichen Intelligenz, der sich mit der Entwicklung von Algorithmen und Technologien befasst, die Computern das Verstehen und Verarbeiten von Audio ermöglichen. Audio Processing-Systeme können Sprache, Musik, Geräusche und andere akustische Signale erkennen, klassifizieren und verarbeiten. Diese Systeme werden in einer Vielzahl von Anwendungen eingesetzt, darunter Spracherkennung, Musikerkennung, Geräuschunterdrückung, Audioanalyse und Sprachsynthese.</span><span data-index="119515e9526" type="3" content="Abseits der Sprachassistenten, die Sie sicher bereits kennen, gibt es auch noch andere Anwendungen. So lassen sich beispielsweise auch Musikstücke generieren, die von einem KI-Modell komponiert wurden. Hierbei wird das Modell mit einer großen Menge an Musikstücken trainiert und kann dann auf Anfrage ein neues Musikstück generieren. Auch hierbei ist es möglich, dass das Modell aufgrund der Trainingsdaten ein Musikstück generiert, das einem bereits bekannten Stück sehr ähnlich ist. Es lassen sich auch Stimmen von bekannten Persönlichkeiten generieren, da es viele Audio-Dateien gibt, die zum Trainieren der Modelle verwendet werden können." data-aos-delay="0" data-aos="fade-right" class="text-6xl md:text-8xl lg:text-10xl aos-init aos-animate" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:0.4;display:block;left:auto;padding:1em 0;color:currentColor;background-clip:text;position:relative;fons-size:0.5em !important;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3))">Abseits der Sprachassistenten, die Sie sicher bereits kennen, gibt es auch noch andere Anwendungen. So lassen sich beispielsweise auch Musikstücke generieren, die von einem KI-Modell komponiert wurden. Hierbei wird das Modell mit einer großen Menge an Musikstücken trainiert und kann dann auf Anfrage ein neues Musikstück generieren. Auch hierbei ist es möglich, dass das Modell aufgrund der Trainingsdaten ein Musikstück generiert, das einem bereits bekannten Stück sehr ähnlich ist. Es lassen sich auch Stimmen von bekannten Persönlichkeiten generieren, da es viele Audio-Dateien gibt, die zum Trainieren der Modelle verwendet werden können.</span></section><section id="section--4" style="display:flex;flex-wrap:wrap;align-items:center;justify-content:flex-start;z-index:20;gap:2em;box-shadow:none;clip-path:polygon(0 6%, 100% 0, 100% 105%, 0 100%)"><h2 data-index="26c3f8695" type="5" data-aos="zoom-out-up" data-aos-anchor-placement="center-center" class="txt" style="display:block;font-weight:500;bottom:auto;position:relative;flex:1 1 100%;margin-top:0;left:auto;align-self:flex-start;color:transparent;background-clip:text;text-align:center;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));background-image:radial-gradient(circle 763px at 0%, rgb(241 197 194) 0%, rgb(245 215 117) 100%)" content="Stimmensynthese">Stimmensynthese</h2><audio data-index="12a68517dae" type="12" src="/not_morgan_freeman.mp3" data-aos-delay="0" data-aos="zoom-out-up" data-aos-anchor-placement="bottom-bottom" class="aos-init aos-animate" style="mix-blend-mode:overlay;backdrop-filter:blur(20px);opacity:0.25;max-width:300px" controls=""></audio><span data-index="db84f19df9" type="3" content="&quot;It is particularly easy to generate voices of famous people, as there are many audio files available for training the models. I&#x27;m not Morgan Freeman but he still gets a freckle for this explanation.&quot;" data-aos-delay="0" data-aos="fade-left" class="text-6xl md:text-8xl lg:text-10xl aos-init aos-animate" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4, rgb(229 213 189) -0.1em 0.1em 0.8em;opacity:1;display:block;left:auto;padding:1em;color:#ffffff;background-color:#00000011;font-style:italic;font-weight:200;border-radius:1em;position:relative;fons-size:5em !important;margin:0;flex:1;filter:drop-shadow(rgba(0, 0, 0, 0.3) -6px -3px 8px) drop-shadow(0 0 1em rgba(229 213 189, 1) )">&quot;It is particularly easy to generate voices of famous people, as there are many audio files available for training the models. I&#x27;m not Morgan Freeman but he still gets a freckle for this explanation.&quot;</span><span data-index="15934cc2e2a" type="3" content="-- not Morgan Freeman" data-aos-delay="0" data-aos="fade-right" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl aos-init aos-animate" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:1;display:block;left:auto;padding:1em 0;background-clip:text;position:relative;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));fons-size:5em !important;color:#ffffff;font-style:italic;font-weight:200;align-self:flex-start;bottom:3em;padding-right:1em;flex-basis:100%;text-align:right">-- not Morgan Freeman</span><span data-index="171602d884c" type="3" content="&quot;Listen, folks, the hands? Perfect size, just ask anyone. And the skin? It&#x27;s a beautiful shade, the best shade, everyone loves it. The people who say otherwise are just jealous, believe me. As for being stupid, that&#x27;s fake news, okay? No one loves people more than me, nobody.&quot;" data-aos-delay="0" data-aos="fade-left" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl aos-init aos-animate" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4, rgb(229 213 189) -0.1em 0.1em 0.8em;opacity:1;display:block;left:auto;padding:1em;color:#ffffff;background-color:#00000011;font-style:italic;font-weight:200;border-radius:1em;position:relative;fons-size:5em !important;margin:0;flex:1;filter:drop-shadow(rgba(0, 0, 0, 0.3) -6px -3px 8px) drop-shadow(0 0 1em rgba(229 213 189, 1) )">&quot;Listen, folks, the hands? Perfect size, just ask anyone. And the skin? It&#x27;s a beautiful shade, the best shade, everyone loves it. The people who say otherwise are just jealous, believe me. As for being stupid, that&#x27;s fake news, okay? No one loves people more than me, nobody.&quot;</span><audio data-index="179430b17e1" type="12" src="/trump.mp3" data-aos-delay="0" data-aos="zoom-out-up" data-aos-anchor-placement="bottom-bottom" class="aos-init aos-animate" style="mix-blend-mode:overlay;backdrop-filter:blur(20px);opacity:0.25;max-width:300px" controls=""></audio><span data-index="ad142d1e82" type="3" content="-- not Donald Trump" data-aos-delay="0" data-aos="fade-right" data-aos-anchor-placement="bottom-bottom" class="text-6xl md:text-8xl lg:text-10xl" style="with:100%;font-weigh:500;text-shadow:0.1em -0.1em 0.4em #450b0ac4;opacity:1;display:block;left:auto;padding:1em 0;margin:0;align-self:flex-start;background-clip:text;bottom:2em;position:relative;filter:drop-shadow(-6px -3px 8px rgba(0, 0, 0, 0.3));fons-size:5em !important;color:#ffffff;font-style:italic;font-weight:200;padding-left:3em;flex-basis:100%">-- not Donald Trump</span></section><svg width="0" height="0"><defs></defs><g><clipPath id="svgPath"><path id="rect1" style="opacity:1;vector-effect:none;fill:transparent;fill-rule:evenodd;stroke-width:1.28465;stroke-dasharray:5695.12;stop-color:#000000;stop-opacity:1" d="M 2.0469091,2.0469081 -2.0469076,571.08744 Z"></path><path id="path1" style="opacity:1;vector-effect:none;fill:#ffffff;fill-rule:evenodd;stroke-width:1.28465;stroke-dasharray:5695.12;stop-color:#000000;stop-opacity:1" d="M 285,-2.1556503e-7 1922.047,2.0469081 1920,1080 800.50158,1077.9531 C 658.92274,974.85075 717.37261,699.89763 475.90623,489.21111 234.43985,278.52458 -159.70464,49.790476 8.187634,-16.375247 92.766804,-49.707585 285,-2.1556503e-7 285,-2.1556503e-7 Z"></path></clipPath></g></svg><footer><div class="flex-col items-center justify-start mx-2 gap-2 flex flex-end"><a href="https://github.com/jibbex"><img class="hover:opacity-100 opacity-40 fill-slate-400 footer-ico size-24 sm:size-32 md:size-46" src="data:image/svg+xml,%3c?xml%20version=&#x27;1.0&#x27;%20encoding=&#x27;utf-8&#x27;?%3e%3c!--%20Generated%20by%20IcoMoon.io%20--%3e%3c!DOCTYPE%20svg%20PUBLIC%20&#x27;-//W3C//DTD%20SVG%201.1//EN&#x27;%20&#x27;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&#x27;%3e%3csvg%20version=&#x27;1.1&#x27;%20xmlns=&#x27;http://www.w3.org/2000/svg&#x27;%20xmlns:xlink=&#x27;http://www.w3.org/1999/xlink&#x27;%20width=&#x27;32&#x27;%20height=&#x27;32&#x27;%20viewBox=&#x27;0%200%2032%2032&#x27;%3e%3cpath%20fill=&#x27;currentColor&#x27;%20d=&#x27;M16%205.343c-6.196%200-11.219%205.023-11.219%2011.219%200%204.957%203.214%209.162%207.673%2010.645%200.561%200.103%200.766-0.244%200.766-0.54%200-0.267-0.010-1.152-0.016-2.088-3.12%200.678-3.779-1.323-3.779-1.323-0.511-1.296-1.246-1.641-1.246-1.641-1.020-0.696%200.077-0.682%200.077-0.682%201.126%200.078%201.72%201.156%201.72%201.156%201.001%201.715%202.627%201.219%203.265%200.931%200.102-0.723%200.392-1.219%200.712-1.498-2.49-0.283-5.11-1.246-5.11-5.545%200-1.226%200.438-2.225%201.154-3.011-0.114-0.285-0.501-1.426%200.111-2.97%200%200%200.941-0.301%203.085%201.15%200.894-0.25%201.854-0.373%202.807-0.377%200.953%200.004%201.913%200.129%202.809%200.379%202.14-1.453%203.083-1.15%203.083-1.15%200.613%201.545%200.227%202.685%200.112%202.969%200.719%200.785%201.153%201.785%201.153%203.011%200%204.31-2.624%205.259-5.123%205.537%200.404%200.348%200.761%201.030%200.761%202.076%200%201.5-0.015%202.709-0.015%203.079%200%200.299%200.204%200.648%200.772%200.538%204.455-1.486%207.666-5.69%207.666-10.645%200-6.195-5.023-11.219-11.219-11.219z&#x27;%3e%3c/path%3e%3c/svg%3e" alt="Github"/></a><div><p class="w-1/2 p-2 text-center text-sm md:text-lg ml-[20vw]">Diese Seite ist Open Source und kann bei Github geklont werden.</p></div></div><div class="items-end justify-end mb-0 mr-8 mt-14 flex flex-end"><div class="m-0"><a class="m-0 mr-2" href="https://michm.de/datenschutz">Datenschutz</a>| </div><div class="m-0"><a class="m-0 ml-2" href="https://michm.de/impressum">Impressum</a></div></div></footer></main></div>
    <style>
        input::-moz-placeholder {
            color: rgb(255 255 255 / 0.6);
            ;
            -moz-transition: all .35s cubic-bezier(0.075, 0.82, 0.165, 1);
            ;
            transition: all .35s cubic-bezier(0.075, 0.82, 0.165, 1);
        }

        input::placeholder {
            color: rgb(255 255 255 / 0.6);
            ;
            transition: all .35s cubic-bezier(0.075, 0.82, 0.165, 1);
        }

        input::-moz-placeholder::focus {
            color: #ffffffca;
        }

        input::placeholder::focus {
            color: #ffffffca;
        }
    </style>
</body>

</html>